\chapter{Results and analysis}\label{chapter:res-analysis}
The objective of this section is to show the effect of running the test benchmarks under SPM's watch. To this end the main indicators to watch are the completion time and throughput. The first part of this chapter deals with the presentations of the results for distgen and LAMA-CG and the second part presents a discussion of these results.
 
\section{SPM and distgen}\label{section:spmydistgen}
This section will discuss the different scenarios that will be used for the testing of distgen as the observed process. For an overview of distgen, please refer to section \ref{section:distgen}.
\subsection{SPM and Distgen with Two Threads}\label{subsection:res-spmydistgen-2t}

\subsubsection{Scenarios Under Consideration}\label{subsection:res-scenarios-2t-scens}

\begin{itemize}
	\item The \textbf{vanilla local scenario} is the code in its original form, two threads are run in the same NUMA node.
	\item The \textbf{vanilla remote scenario}: Each thread runs on a separate NUMA node. The first thread initializes the memory space and the second thread accesses it. 
	\item The \textbf{SPM scenario} is the same as the vanilla remote scenario but this time the program execution will be overseen by the SPM tool and the pages observed to be accessed more from a remote node are moved to the node that originates the greater number of memory accesses.
	\item The \textbf{moveall} scenario is a distgen modification based on vanilla remote that after a determinate time of execution, will move all the memory pages from a remote node to a local node.
\end{itemize}

Every one of this scenarios has a special significance for the measurement of the performance: The vanilla local scenario shows the maximum speed possible for the given algorithm, vanilla remote will show how much performance deteriorates when the algorithm is forced to perform many remote accesses in order to fetch the required data, moveall is a reference scenario that tells how much it is possible to fix the performance degradation by taking the pages placed in a remote node and bringing them close to the executing node and SPM also tries to fix the slowdown caused by the remote placement of the pages, but since the SPM does not know about the internal implementation of the supervised process, it will only move the pages that the PMU reports as remote accesses. The closer SPM's results are to the moveall scenario, the best performing the SPM tool is. Figures \ref{fig:dgentt-local} and \ref{fig:dgentt-remote} present depictions of both local and remote vanilla scenarios.

In order to be able to be able to place the pages remotely, a modification has to be made to the original distgen code, where the initialization is done by the master thread and the access is done only by the other thread, which is not the master. To determine whether the two threads are placed in the same NUMA node the environment variable \textit{GOMP\_CPU\_AFFINITY} is manipulated in order to determine the core in which the running threads will be placed. The availability of this modified two threads version is described in code listing 5 in Appendix \ref{app:coderes}.

\begin{figure}
	\centering
		\includegraphics[width=.7\textwidth]{figures/distgentt-local.eps}
		\caption[Depiction of the working of the distgen vanilla local scenario with two threads]{Depiction of the distgen vanilla local with two running threads. Both threads are in the same NUMA node, therefore only local accesses will be performed.}
		\label{fig:dgentt-local}
\end{figure}

\begin{figure}
	\centering
		\includegraphics[width=.7\textwidth]{figures/distgentt-remote.eps}
		\caption[Depiction of the working of the distgen vanilla remote scenario with two threads]{Depiction of the distgen vanilla remote with two running threads. Each thread is pinned to a different NUMA node, which causes a lot of remote accesses to be done by the running thread.}
		\label{fig:dgentt-remote}
\end{figure}
\FloatBarrier
\subsubsection{Performance for the Random Mode}\label{subsection:res-dgrandom-2t-scens}

\begin{table}
	\centering
		\begin{tabularx}{.9\textwidth}{|l|l|l|l|X|}
		\hline
			Size & Vanilla local & Vanilla Remote & Moveall after 45s & SPM \\
			 & time(s) & time(s) & time(s) & time(s)  \\
			\hline
			400G & 61 & 102 & 85 & 80\\
			\hline
			600G & 91 & 154 & 124 & 134\\
			\hline
			800G & 125 & 215 & 200 & 187\\
			\hline
			1T & 151 & 260 & 198 & 202\\
			\hline
		\end{tabularx}
		\caption{Execution time given in seconds of the different distgen scenarios in random mode with two running threads. Sampling period 100 instructions/sample and minimum weight threshold 150.}
		\label{table:res-dgentimrdm2t}
\end{table}

\begin{table}
	\centering
		\begin{tabularx}{.9\textwidth}{|l|l|l|l|X|}
		\hline
			Size & Vanilla local & Vanilla Remote & Moveall after 45s & SPM \\
			 & reads/s & reads/s & reads/s & reads/s  \\
			\hline
			400G & 1.12E+08 & 6.77E+07 & 1.01E+08 & 9.68E+07\\
			\hline
			600G & 1.13E+08 & 6.74E+07 & 8.24E+07 & 9.35E+07\\
			\hline
			800G & 1.10E+08 & 6.45E+07 & 7.36E+07 & 7.10E+07\\
			\hline
			1T & 1.14E+08 & 6.66E+07 & 8.85E+07 & 9.39E+07\\
			\hline
		\end{tabularx}
		\caption{Execution throughput given in reads per second of the different distgen scenarios in random mode. Sampling period 100 instructions/sample and minimum weight threshold 150.}
		\label{table:res-dgentrgrdm2t}
\end{table}

\begin{table}
	\centering
		\begin{tabularx}{.6\textwidth}{|l|l|X|}
		\hline
			Size & Moved pages & Moved pages \%  \\
			\hline
			400G & 422971 & 108 \\
			\hline
			600G & 372289 & 63 \\
			\hline
			800G & 413297 & 52 \\
			\hline
			1T & 423478 & 43 \\
			\hline
		\end{tabularx}
		\caption{Number of pages moved by the SPM tool for the random distgen scenario with two threads. Sampling period 100 instructions/sample and minimum weight threshold 150.}
		\label{table:res-dgenmvdrdm2t}
\end{table}


\begin{figure}[th]
	\centering
		\includegraphics[width=.8\textwidth]{figures/time-dgentt-random.eps}
		\caption{Normalized execution times for the different scenarios of distgen random with two threads shown in table \ref{table:res-dgentimrdm2t} relative to the vanilla case.}
		\label{fig:res-dgentimrdm2t}
\end{figure}

\begin{figure}[th]
	\centering
		\includegraphics[width=.8\textwidth]{figures/thrput-dgentt-randm.eps}
		\caption{Normalized execution throughput for the different scenarios of distgen random with two threads shown in table \ref{table:res-dgentrgrdm2t} relative to the vanilla case.}
		\label{fig:res-dgentrgrdm2t}
\end{figure}

Tables \ref{table:res-dgentimrdm2t} and \ref{table:res-dgentrgrdm2t} show the results of the execution of the different scenarios of distgen random. Figures \ref{fig:res-dgentimrdm2t} and \ref{fig:res-dgentrgrdm2t} show the execution times and throughputs respectively as a normalized quantity with respect to the distgen vanilla result, which means that a value closer to 1 resembles a performance closer to that obtained in the local algorithm. In this random setting with two threads, SPM did a very good job with a performance very similar to the moveall situation, which is the theoretical maximum that can be reached. Another important result that appears in most of the measurements, is that the performance of the moveall strategy after moving the pages never gets to be the same as that obtained in the local version, effect that has to be researched further.
As for the performance of the SPM it can be seen from table \ref{table:res-dgenmvdrdm2t} that the percentage of captured pages remain above 40 percent with decreasing value as the domain gets bigger. This happens because with a bigger domain size the observation time occupies a smaller relative portion of the total execution time and therefore less samples can be captured.

\FloatBarrier
\subsubsection{Performance for the Sequential Mode}\label{subsection:res-dgseq-2t}

\begin{table}[th]
	\centering
		\begin{tabularx}{.9\textwidth}{|l|l|l|l|X|}
		\hline
			Size & Vanilla local & Vanilla Remote & SPM & Moveall after 45s  \\
			 & time(s) & time(s) & time(s) & time(s)  \\
			\hline
			400G & 55 & 92  & 75 & 75\\
			\hline
			600G & 83 & 138 & 117 & 104 \\
			\hline
			800G & 111 & 185 & 159 & 133 \\
			\hline
			1T & 139 & 231 & 199 & 163 \\
			\hline
		\end{tabularx}
		\caption{Execution time for the different scenarios of the distgen sequential algorithm with units given in seconds. Sampling period 100 instructions/sample and minimum weight threshold 150.}
		\label{table:res-tbl-dgentimseq2t}
\end{table}

\begin{table}[th]
	\centering
		\begin{tabularx}{\textwidth}{|l|l|l|l|X|}
		\hline
			Size & Vanilla local & Vanilla Remote & Moveall after 45s & SPM \\
			 & reads/s & reads/s & reads/s & reads/s  \\
			\hline
			400G & 2.48E+08 & 1.50E+08 & 2.37E+08& 2.37E+08\\
			\hline
			600G & 2.48E+08 & 1.50E+08  & 2.37E+08 & 1.96E+08\\
			\hline
			800G & 2.48E+08 & 1.50E+08 & 2.37E+08 & 1.86E+08 \\
			\hline
			1T & 2.48E+08 & 1.50E+08 & 2.37E+08 & 1.48E+08 \\
			\hline
		\end{tabularx}
		\caption{Execution throughput for the different scenarios of the distgen sequential algorithm with units given in reads per second. Sampling period 100 instructions/sample and minimum weight threshold 150.}
		\label{table:res-dgentrgseq2t}
\end{table}

\begin{table}[th]
	\centering
		\begin{tabularx}{.6\textwidth}{|l|l|X|}
		\hline
			Size & Moved pages & Moved pages \%  \\
			\hline
			400G & 232777 & 59.5 \\
			\hline
			600G & 234551 & 40.0\\
			\hline
			800G & 226748 & 29.0 \\
			\hline
			1T & 233191 & 23.9 \\
			\hline
		\end{tabularx}
		\caption{Number of pages moved by spm in the distgen sequential scenario with two threads. Sampling period 100 instructions/sample and minimum weight threshold 150.}
		\label{table:res-dgenmvdseq2t}
\end{table}

\begin{figure}
	\centering
		\includegraphics[width=.7\textwidth]{figures/time-dgentt-ser.eps}
		\caption{Normalized execution speed for the different scenarios of  distgen sequential with two threads with respect to the vanilla local scenario shown in table \ref{table:res-tbl-dgentimseq2t}.}
		\label{fig:res-dgentimseq2t}
\end{figure}

\begin{figure}
	\centering
		\includegraphics[width=.7\textwidth]{figures/thrput-dgentt-ser.eps}
		\caption{Normalized execution throughput for the different scenarios of the distgen sequential with two threads with respect to the vanilla local scenario shown in table \ref{table:res-dgentrgseq2t}.}
		\label{fig:res-dgentrgseq2t}
\end{figure}


In this opportunity the serial version of distgen is run. Because of the faster running time of this algorithm, the number of iterations is doubled to 2000 to obtain a long enough execution time that allows to observe the influence of SPM. Tables \ref{table:res-tbl-dgentimseq2t} and \ref{table:res-dgentrgseq2t} show the execution time and performance results and Figures \ref{fig:res-dgentimseq2t} and \ref{fig:res-dgentrgseq2t} show the normalized values with respect to distgen vanilla. In comparison to the serial version the performance of the SPM tool is not as good and only matches that of the moveall scenario with the smallest size. Part of this slowdown can be explained by the smaller portion of pages that the tool is getting, as shown in table \ref{table:res-dgenmvdseq2t}.

\subsection{SPM and Distgen with all Threads Employed}\label{subsection:res-spmydistgen-at}

The scenarios used here follow the same logic as what was shown in the previous section, but now the goal is to go further and try a contention scenario where more cores are running the algorithm. For this test all the cores except two were used, one of the remaining ones is used to run SPM. In the remote cases, every core is mapped to a core in the opposed NUMA node and the data will be allocated in this remote node.

Table \ref{table:res-dgentimrdmat} shows the run times for the scenarios under the random case and figure \ref{fig:time-dgenatt-ser} shows the normalized results. These results show that the performance of the tool locate very close to the best possible. Table \ref{table:res-tbl-dgenmvdrdmat} confirms that a good coverage of the computing domain was reached. The random cases were run with 2000 iterations.

For the sequential case table \ref{table:res-dgentimserat} shows the completion time information, having in mind that the number of iterations is 4000 and figure \ref{fig:time-dgenatt-ser} shows these quantities normalized. Unlike the random case the improvement is not so good, locating itself between the worst and possible cases. Table \ref{table:res-tbl-dgenmvdseqat} could point to a possible cause to be the lowest coverage of the computing domain obtained.

\begin{table}[th]
	\centering
		\begin{tabularx}{.9\textwidth}{|l|l|l|l|X|}
		\hline
			Size & Vanilla local & Vanilla Remote & Moveall after 45s & SPM \\
			 & time(s) & time(s) & time(s) & time(s)  \\
			\hline
			90G & 83 & 196 & 152 & 155\\
			\hline
			110G & 103 & 242 & 184 & 191\\
			\hline
			130G & 129 & 282 &194 & 210\\
			\hline
			150G & 141 & 329 & 260 & 254\\
			\hline
		\end{tabularx}
		\caption{Completion time in seconds for the random distgen with 30 threads employed. Sampling period 10 instructions/sample, 1000 iterations and minimum weight threshold 150.}
		\label{table:res-dgentimrdmat}
\end{table}

\begin{figure}[th]
	\centering
		\includegraphics[width=.8\textwidth]{figures/time-dgenat-random.eps}
		\caption{Normalized execution time for the random distgen cases with 30 threads employed shown in table \ref{table:res-dgentimrdmat}.}
		\label{fig:res-dgentimrdmat}
\end{figure}


\begin{table}[th]
	\centering
		\begin{tabularx}{.9\textwidth}{|l|l|l|l|X|}
		\hline
			Size & Vanilla local & Vanilla Remote & Moveall after 45s & SPM \\
			& time(s) & time(s) & time(s) & time(s)  \\
			\hline
			90G & 127 & 341 & 152 & 262\\
			\hline
			110G & 156 & 417& 184 & 331\\
			\hline
			130G & 184 & 493 & 194 & 395\\
			\hline
			150G & 212 & 569 & 260 & 465\\
			\hline
		\end{tabularx}
		\caption{Execution time for the sequential distgen cases with 30 threads employed and 4500 iterations. Sampling period 10 instructions/sample and minimum weight threshold 150.}
		\label{table:res-dgentimserat}
\end{table}

\begin{figure}[th]
	\centering
		\includegraphics[width=.8\textwidth]{figures/time-dgenatt-ser.eps}
		\caption{Normalized execution time for the sequential distgen cases with 30 threads employed shown in table \ref{table:res-dgentimserat}.}
		\label{fig:time-dgenatt-ser}
\end{figure}

\begin{table}[th]
	\centering
		\begin{tabularx}{.6\textwidth}{|l|l|X|}
		\hline
			Size & Moved pages & Moved pages \%  \\
			\hline
			90G & 4438270 & 84 \\
			\hline
			110G & 4556914 & 54\\
			\hline
			130G & 3526065 & 46 \\
			\hline
			150 & 4647763 & 52\\
			\hline
		\end{tabularx}
		\caption{Number of moved pages by the SPM tool for the distgen random case with 30 active threads. Sampling period 10 instructions/sample and minimum weight threshold 150.}
		\label{table:res-tbl-dgenmvdrdmat}
\end{table}


\begin{table}[th]
	\centering
		\begin{tabularx}{.6\textwidth}{|l|l|X|}
		\hline
			Size & Moved pages & Moved pages \%  \\
			\hline
			90G & 770653 & 13.700 \\
			\hline
			110G & 809007 & 11.767 \\
			\hline
			130G & 809901 & 9.968 \\
			\hline
			150 & 853033 & 9.099\\
			\hline
		\end{tabularx}
		\caption{Number of moved pages by the SPM tool for the distgen sequential case with 30 threads shown in table \ref{table:res-dgentimserat}. Sampling period 10 instructions/sample and minimum weight threshold 150}
		\label{table:res-tbl-dgenmvdseqat}
\end{table}
\FloatBarrier
\subsubsection{Measuring the Effect of SPM's Action}\label{subsection:time-dgenat-action.eps}

A more detailed way to appreciate the improvements in performance of the SPM is to look at the information provided by the performance readings: the first one is the average number of executed instructions, which is shown in figure \ref{fig:at-spmactn-thgput} as a function of time. After the end of the observation period there are more instructions executed. 

The second way to verify the action of SPM is to look at the performances average values of local and remote memory traffic, which are shown in figure \ref{fig:at-spmactn-trsfer}. After the end of the observation phase, the local traffic increases and the remote decreases working in favor of a more efficient execution of the observed algorithm.

\begin{figure}[th]
	\centering
		\includegraphics[width=.8\textwidth]{figures/at-thrput-random.eps}
		\caption{View of the average throughput during the execution of distgen under SPM supervision in the distgen SPM case with 30 active threads and a domain of size 110G. The page migration is done at time 45 with a minimum weight threshold of 150.}
		\label{fig:at-spmactn-thgput}
\end{figure}

\begin{figure}[th]
	\centering
		\includegraphics[width=.8\textwidth]{figures/at-transfer-random.eps}
		\caption{View of the average and local and remote transfer rates during the execution of distgen under SPM supervision in the distgen SPM case with 30 active threads and a domain of size 110G. The page migration is done at time 45 with a minimum weight threshold of 150.}
		\label{fig:at-spmactn-trsfer}
\end{figure}


\section{SPM and LAMA-CG}\label{section:spmylamacg}


\begin{figure}
	\centering
		\includegraphics[width=.7\textwidth]{figures/lam3k.eps}
		\caption{Completion time for different combinations of period and sample time for LAMA-CG with a square matrix with side 3000 and minimum weight threshold of 150.}
		\label{fig:res-lamatim-3k}
\end{figure}

\begin{figure}
	\centering
		\includegraphics[width=.7\textwidth]{figures/lam3k750.eps}
		\caption{Completion time for different combinations of period and sample time for LAMA-CG with a square matrix with side 3750 and minimum weight threshold of 150.}
		\label{fig:res-lamatim-3k45}
\end{figure}

For the execution of LAMA-CG a contention situation with 30 threads will be used to test the action of SPM, leaving one for the execution of the SPM tool. This time the source code of the observed algorithm will not be modified, but in order to create a situation with many remote accesses involved, the re-pinning of the threads was induced 15 seconds after starting the algorithm in such a way that every thread was reallocated to a core located in the opposite NUMA node and then SPM was started as usual.

\begin{figure}
	\centering
		\includegraphics[width=.7\textwidth]{figures/lam4k.eps}
		\caption{Completion time for different combinations of period and sample time for LAMA-CG with a square matrix with side 4500 and minimum weight threshold of 150.}
		\label{fig:res-lamatim-4k}
\end{figure}

For the study of LAMA-CG under SPM a variation of parameters was done by trying sampling periods of 10, 20 and 50 instructions per sample and observation phase times of 60 and 120 seconds. Three domain sizes were used, which were square matrices of length 3000, 3750 and 4500.


\begin{figure}[th]
	\centering
		\includegraphics[width=.7\textwidth]{figures/lama-thrput.eps}
		\caption{Average executed instructions as a function of time for the executions of LAMA-CG with measurement time of 60 seconds, matrix size of 3750 and minimum weight threshold of 150.}
		\label{fig:res-lamatrg}
\end{figure}

\begin{figure}[t]
	\centering
		\includegraphics[width=.8\textwidth]{figures/lama-localtr.eps}
		\caption{Average local memory traffic as a function of time for the executions of LAMA-CG with measurement time of 60 seconds, matrix size of 3750 and minimum weight threshold of 150.}
		\label{fig:res-lamaloctr}
\end{figure}

\begin{figure}[t]
	\centering
		\includegraphics[width=.8\textwidth]{figures/lama-remotetr.eps}
		\caption{Average remote memory traffic as a function of time for the executions of LAMA-CG with measurement time of 60 seconds and matrix size of 3750 and minimum weight threshold of 150..}
		\label{fig:res-lamaremotr}
\end{figure}

Figures \ref{fig:res-lamatim-3k}, \ref{fig:res-lamatim-3k45} and \ref{fig:res-lamatim-4k} show the run time results for the different scenarios described above. The results show that the best times are obtained with the lowest period of 10 instructions per sample. The biggest observation time was only best for the biggest size.

Figure \ref{fig:res-lamatrg} shows the throughput readings for the different scenarios of the matrix with size 3750 and observation time of 60 seconds: the original version is the best case with the highest throughput and the flipped version is the worst case because a lot of remote accesses are performed. The other three cases show the intervention of the SPM tool after 60 seconds of re-pinning the threads. The readings for local memory and remote memory transfers are shown in figures \ref{fig:res-lamaloctr}, and \ref{fig:res-lamaremotr} respectively.

\section{Co-location and Statistical Significance}\label{section:resssigni}

\begin{figure}
	\centering
		\includegraphics[width=.8\textwidth]{figures/signi-ran.eps}
		\caption{Results for running the distquen random with array size 110G with 30 threads active with sampling period 10 instructions/sample and minimum weight filter of 150. The number of iterations for the random case is 2000 and for the sequential 4000. The left side shows the completion time and the right one shows the number of moved pages for different page access threshold}
		\label{fig:res-signiran}
\end{figure}


\begin{figure}
	\centering
		\includegraphics[width=.8\textwidth]{figures/signi-seq.eps}
		\caption{Results for running the distquen serial with array size 110G with 30 threads active with sampling period 10 instructions/sample and minimum weight filter of 150. The left side shows the completion time and the right one shows the number of moved pages for different page access threshold}
		\label{fig:res-signiseq}
\end{figure}


So far the results shown for SPM have been applied for a co-location, which considers the node with the highest number of page accesses the home of the node, and the page will be migrated even if it is only accessed once by the node thought to be the home of the page. But the question which this choice raises is whether one page access is significant enough to be allocated to a given node and many times a higher value would be desired to make the home allocation decision of the pages in question. 

SPM incorporates the option of applying a frequency threshold which specifies the number of page accesses after a node is considered to be the home of a page. Usually every algorithm has a predominant number of times a page is accessed. For the random version of distgen this number lies between 11 and 40 and for the sequential between 3 and 8. Using the page access frequency filter the algorithms were run and the results are given in figures \ref{fig:res-signiran} and \ref{fig:res-signiseq}. For the random version of distgen, it can be seen that the filter value of 10 does not affect the completion time in a great manner, but for a value of 20 the number of captured pages drops to approximately half. In the sequential case a filter of five decreases the number of captured pages in 9\% and the run time is increased in 10\%. For a threshold value of 10 the number of moved pages already decreases 37\%.
The previous information leads to state that increasing the page access threshold helps be more certain of the move page decision, but it must be tuned carefully to the executed algorithm in order to avoid reducing significantly the number of moved pages

\section{Contention Analysis}\label{section:rescont}

\begin{table}
	\centering
		\begin{tabularx}{.5\textwidth}{|l|X|}
		\hline
			Home Switches & Frequency   \\
			\hline
			0 & 282723
   \\
			\hline
			1 & 7454
   \\
			\hline
			2 & 3850 \\
			\hline
			3 & 233  \\
			\hline
			4 & 2855  \\
			\hline
			5 & 211  \\
			\hline
			6 & 2137  \\
			\hline
			7 & 215  \\
			\hline
			8 & 1820  \\
			\hline
			9 & 227  \\
			\hline
			10 & 1657 \\
			\hline
			$>$10 & 6899 \\
			\hline
		\end{tabularx}
		\caption{Number of home switches for a run of LAMA-CG run with a sampling period of 10 instructions per sample, minimum weight filter of 150 and matrix size of 3750.}
		\label{table:res-dgencontent}
\end{table}

In SPM the ability to detect the contention for a page between nodes was implemented. Every time SPM receives a sample concerning a given page, it will store which node was the last one to access it. Whenever a page is accessed by a node other than the one that last accessed it, a situation called a home switch occurs. For the versions of distgen it was found that the number of page switches is very small with 0 home switches being the dominant frequency, for values of one page switch the number of pages is less than the 10 percent of the frequency for 0 switches and for values greater than 2 this number is negligible. This means that the versions of distgen are very well localized and incur in very small contention. For LAMA-CG there is a greater amount of contention as shown in table \ref{table:res-dgencontent}, but still the frequencies for values greater than 0 are significantly smaller.
\FloatBarrier
\section{Results discussion}\label{section:resdiscussion}
The obtained results point to an important dependence between the number of obtained samples and both the sampling frequency and the observation phase time, but also the nature of the algorithm plays an important role. For the distgen scenarios, the best performance was obtained by the random scenarios obtaining a better coverage of the memory space than the sequential version. LAMA-CG also appears to show a sequential like behavior. The reduced number of obtained samples under the sequential scenarios appears to present itself because of the sampling system not capturing the prefetcher induced traffic, which is so frequently present in the sequential memory access patterns. For the length of the observation period the tool is more successful for more iterations over a smaller space than for less iterations over a larger space. This happens because the probability of sampling a given page increases in the first case. 

The choice of the sampling period is crucial, and for most of the runs in these document the greatest number of samples was obtained for a period of 10 instructions per sample. Less than that value fewer samples were obtained. The tool does better when it gets allocated its own thread, because when the observed algorithm runs on all the threads two bad effects happen: first the observed algorithm must compete with SPM which means that one core will not reach full throughput when the others will, and during the page migration phase SPM will need to get the most of a core performance. The other is that because of the reduced, performance SPM will be able to process less samples, which means that less candidate samples for the migration will be produced.

